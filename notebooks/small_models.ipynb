{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-1b9b54892aca>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-1b9b54892aca>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    mobilenetv2 vs efficientnet\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Problem 1 : Size of model \n",
    "Problem 2 : Speed of model\n",
    "# choice of backend \n",
    "# mobilenetv2 vs efficientnet\n",
    "\n",
    "# tflite for fast model on CPU\n",
    "# quantization for running on edge hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-573150d8af03>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-573150d8af03>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Pose Models of two types:\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exercising is moving between states. So we need following:\n",
    "1] Pose detection model that can run at real time on cheap and easily available hardware\n",
    "    Hardware:\n",
    "    1] JetsonNano, RaspberryPi, Mobile, EdgeTPU, Laptop\n",
    "    2] Cost, availability, practicality\n",
    "    3] For this demo, laptop + edgetpu\n",
    "    \n",
    "    Training your model:\n",
    "        1] Train a model for segmentation which works at 30fps on CPU and is less than 4MB. \n",
    "        Why ? Small models can be updated over network.\n",
    "        2] Tricks\n",
    "            a] Pruning\n",
    "            b] Quantization:fp16, int8\n",
    "            c] TFLite\n",
    "    \n",
    "    Models lose accuracy when we make them smaller and faster. So now we have 2 models, one accurate and another fast. \n",
    "    We combine them to improve accuracy:\n",
    "    1] By training a kalman filter like structure. Can be trained online or offline\n",
    "    2] By running one accurate and one fast model in parallel\n",
    "        a] Running models in parallel on different devices : CPU + GPU + TPU\n",
    "        b] Feed accurate models input to kalman filter for better state updates\n",
    "    3] Measuring accuracy\n",
    "        a] Two models running in parallel lets us compute runtime accuracy\n",
    "        \n",
    "2] Break an exercise into stages, and when a person goes through all stages of an exercise, the exercise finishes\n",
    "    a] Match pose of person with target pose\n",
    "    b] No standard metric to measure distance between two poses\n",
    "    c] Three approaches:\n",
    "        1.Train a classifier to classify poses, either use already available datasets\n",
    "        2.Prepare own dataset by scraping google with yoga pose names\n",
    "        3.Use videos to train a siamese network, frames which are further in the video, should be less similar\n",
    "        4.Use existing similarity metric between pose vectors\n",
    "\n",
    "3] Feedback\n",
    "    a] What can we show the user ? \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
